{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b124c2d7-baac-43c6-beb8-f2662fa78fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2663],\n",
      "        [-0.1317]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([100, 100])\n",
      "tensor([[-0.2663],\n",
      "        [-0.1317]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.1623],\n",
      "        [-0.2971]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.2663],\n",
      "        [-0.1317]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.2711],\n",
      "        [-0.1303]], grad_fn=<SliceBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# SVDrop: A method to drop out singular vectors from a representation learned by a neural network\n",
    "\n",
    "# Method consists of:\n",
    "\n",
    "# 1. Calculate SVD of features from DNN\n",
    "# 2. Premultiply classifier by the following V^-1 DropoutVector V\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "import torch.nn.init as init\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from random import randint\n",
    "\n",
    "class SVDropClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor a \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.V = None\n",
    "        self.Lambda = None\n",
    "\n",
    "        self.mu_R = None\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        self.reset_mask()\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "        init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def set_singular(self, V: Tensor, mu: Tensor) -> None:\n",
    "        self.V = V                           # Right singular vectors of R\n",
    "        self.s_values = Lambda               # List of singular values of R\n",
    "        self.V_inv = torch.linalg.pinv(V)    # Pseudoinverse of V\n",
    "        self.mu_R = mu\n",
    "        self.Lambda = torch.diagflat(self.mask)\n",
    "        \n",
    "    def reset_singular(self) -> None:\n",
    "        self.V = None\n",
    "        self.Lambda = None\n",
    "        self.V_inv = None\n",
    "        self.mu_R = None\n",
    "        self.s_values = None\n",
    "\n",
    "    def dropout_dim(self, indices=None):\n",
    "        if indices is None: # Randomly drop one index\n",
    "            indices =  [randint(0, self.in_features)] # Choose a random dimension\n",
    "        self.mask[indices] = 0\n",
    "        self.Lambda = torch.diagflat(self.mask)\n",
    "\n",
    "    def reset_mask(self):\n",
    "        self.mask = torch.ones(self.in_features)\n",
    "        self.Lambda = torch.diagflat(self.mask)\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        if self.V is not None: # I want to remove some of my right singular directions!\n",
    "            new_weights = (((self.V @ self.Lambda) @ self.V_inv) @ self.weight.T).T\n",
    "            new_bias = (-self.mu_R*(new_weights - self.weight)).sum() + self.bias\n",
    "            return F.linear(input, new_weights, new_bias)\n",
    "        else: # I'm just a regular linear layer\n",
    "            return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'\n",
    "\n",
    "a = SVDropClassifier(100,1)\n",
    "data = torch.randn(1000,100)\n",
    "print(a(data)[0:2])\n",
    "S,V,D = torch.linalg.svd(data)\n",
    "mu = data.mean(dim=0)\n",
    "print(a.Lambda.shape)\n",
    "a.set_singular(D,mu)\n",
    "print(a(data)[0:2])\n",
    "a.dropout_dim([0,1])\n",
    "print(a(data)[0:2])\n",
    "a.reset_mask()\n",
    "print(a(data)[0:2])\n",
    "a.dropout_dim()\n",
    "print(a(data)[0:2])\n",
    "print(a.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f2850eff-bf96-4cde-a69b-a59091a1d217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
